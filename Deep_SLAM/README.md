Uma extensÃ£o hÃ­brida do ORB-SLAM integrando redes neurais profundas para SLAM visual robusto em robÃ´s mÃ³veis


ğŸ“‹ Resumo

O Neural ORB-SLAM Ã© uma arquitetura hÃ­brida inovadora que combina a robustez de redes neurais profundas com a precisÃ£o da otimizaÃ§Ã£o geomÃ©trica clÃ¡ssica do ORB-SLAM. O sistema substitui componentes tradicionais por mÃ³dulos de deep learning estado-da-arte:
ComponenteMÃ©todo OriginalMÃ©todo NeuralExtraÃ§Ã£o de FeaturesORBSuperPointFeature MatchingForÃ§a BrutaSuperGlueEstimaÃ§Ã£o de ProfundidadeN/AMiDaS v3.1Filtragem DinÃ¢micaRANSACYOLOv8Loop ClosingDBoW2NetVLAD

ğŸ¯ Resultados Principais

Avaliado no benchmark KITTI Odometry:
MÃ©tricaORB-SLAM2ORB-SLAM3DROID-SLAMNeural ORB-SLAMATE (m) â†“15.4211.876.238.91Taxa Tracking â†‘74.3%82.1%99.2%91.8%FPS â†‘31.229.88.418.3

âœ… Melhorias AlcanÃ§adas

ğŸ“‰ 42.2% de reduÃ§Ã£o no erro de trajetÃ³ria vs ORB-SLAM2
ğŸ“ˆ 23.7% de melhoria na taxa de tracking
âš¡ 2.18Ã— mais rÃ¡pido que DROID-SLAM
ğŸŒ™ 8.3% de degradaÃ§Ã£o com variaÃ§Ã£o de iluminaÃ§Ã£o (vs 34.2% do ORB-SLAM2)


ğŸ—ï¸ Arquitetura
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Imagem It  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                       â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ SuperPoint  â”‚         â”‚    MiDaS    â”‚
             â”‚  (Features) â”‚         â”‚   (Depth)   â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â–¼                       â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  SuperGlue  â”‚         â”‚   YOLOv8    â”‚
             â”‚  (Matching) â”‚         â”‚  (Filter)   â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    PnP + RANSAC       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Bundle Adjustment   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                       â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Mapa 3D   â”‚         â”‚   Pose Tt   â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   NetVLAD   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Loop Closingâ”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸš€ InstalaÃ§Ã£o
PrÃ©-requisitos

Sistema Operacional: Ubuntu 20.04/22.04 LTS
GPU: NVIDIA com CUDA 11.8+ (mÃ­nimo 6GB VRAM)
Python: 3.8+
RAM: 16GB (recomendado 32GB)

InstalaÃ§Ã£o RÃ¡pida
bash# 1. Clonar repositÃ³rio
git clone https://github.com/rodrigolucas/neural-orbslam.git
cd neural-orbslam

# 2. Criar ambiente virtual
conda create -n neural-orbslam python=3.10
conda activate neural-orbslam

# 3. Instalar PyTorch com CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. Instalar dependÃªncias
pip install -r requirements.txt

# 5. Baixar modelos prÃ©-treinados
python scripts/download_models.py

# 6. Compilar componentes C++ (opcional)
mkdir build && cd build
cmake .. && make -j$(nproc)
DependÃªncias de Sistema
bashsudo apt update
sudo apt install -y \
    build-essential cmake git \
    libopencv-dev libopencv-contrib-dev \
    libeigen3-dev libglew-dev libboost-all-dev \
    libgl1-mesa-glx libegl1-mesa

ğŸ“– Uso
ExecuÃ§Ã£o BÃ¡sica
bash# Processar sequÃªncia KITTI
python run_slam.py --input data/kitti/00 --output results/

# Com visualizaÃ§Ã£o em tempo real
python run_slam.py --input data/kitti/00 --visualize

# Usar apenas cÃ¢mera monocular
python run_slam.py --input video.mp4 --mode mono
ConfiguraÃ§Ã£o
yaml# config/default.yaml
model:
  superpoint:
    weights: "models/superpoint_v1.pth"
    nms_radius: 4
    keypoint_threshold: 0.005
    max_keypoints: 1024
  
  midas:
    weights: "models/dpt_large_384.pt"
    input_size: 384
  
  yolov8:
    weights: "models/yolov8n-seg.pt"
    confidence: 0.5
    classes: [0, 2, 3, 5, 7]  # person, car, motorcycle, bus, truck

slam:
  tracking:
    min_matches: 15
    ransac_threshold: 1.0
  
  mapping:
    keyframe_threshold: 0.8
    local_window_size: 10
API Python
pythonfrom neural_orbslam import NeuralORBSLAM

# Inicializar sistema
slam = NeuralORBSLAM(config="config/default.yaml")

# Processar frame
for frame in video_stream:
    pose, map_points = slam.process(frame)
    
    if pose is not None:
        print(f"PosiÃ§Ã£o: {pose.translation}")
        print(f"Pontos no mapa: {len(map_points)}")

# Salvar resultados
slam.save_trajectory("trajectory.txt")
slam.save_map("map.ply")

ğŸ“Š AvaliaÃ§Ã£o
Executar Benchmarks
bash# Avaliar no KITTI
python evaluate.py --dataset kitti --sequences 00 01 02 03 04 05

# Comparar com baselines
python evaluate.py --dataset kitti --compare orbslam2 orbslam3

# Gerar relatÃ³rio
python evaluate.py --dataset kitti --report results/report.pdf
MÃ©tricas DisponÃ­veis

ATE (Absolute Trajectory Error): Erro absoluto apÃ³s alinhamento Sim(3)
RPE (Relative Pose Error): Drift relativo entre frames
Taxa de Tracking: Percentual de frames processados com sucesso
FPS: Frames por segundo de processamento


ğŸ“ Estrutura do Projeto

neural-orbslam/
â”œâ”€â”€ config/                 # Arquivos de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ default.yaml
â”‚   â””â”€â”€ kitti.yaml
â”œâ”€â”€ data/                   # Datasets e sequÃªncias
â”‚   â””â”€â”€ kitti/
â”œâ”€â”€ models/                 # Pesos dos modelos prÃ©-treinados
â”‚   â”œâ”€â”€ superpoint_v1.pth
â”‚   â”œâ”€â”€ superglue_outdoor.pth
â”‚   â”œâ”€â”€ dpt_large_384.pt
â”‚   â””â”€â”€ yolov8n-seg.pt
â”œâ”€â”€ src/                    # CÃ³digo fonte
â”‚   â”œâ”€â”€ neural_orbslam/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ slam.py
â”‚   â”‚   â”œâ”€â”€ tracking.py
â”‚   â”‚   â”œâ”€â”€ mapping.py
â”‚   â”‚   â””â”€â”€ loop_closing.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ superpoint.py
â”‚   â”‚   â”œâ”€â”€ superglue.py
â”‚   â”‚   â”œâ”€â”€ midas.py
â”‚   â”‚   â””â”€â”€ yolov8_filter.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ geometry.py
â”‚       â”œâ”€â”€ visualization.py
â”‚       â””â”€â”€ evaluation.py
â”œâ”€â”€ scripts/                # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ download_models.py
â”‚   â”œâ”€â”€ convert_dataset.py
â”‚   â””â”€â”€ calibrate_camera.py
â”œâ”€â”€ tests/                  # Testes unitÃ¡rios
â”œâ”€â”€ docs/                   # DocumentaÃ§Ã£o
â”œâ”€â”€ results/                # Resultados de experimentos
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md

ğŸ”¬ CitaÃ§Ã£o

Se vocÃª usar este trabalho em sua pesquisa, por favor cite:
bibtex@article{santos2024neuralorbslam,
  title={Neural ORB-SLAM: Uma ExtensÃ£o HÃ­brida do ORB-SLAM Integrando 
         Redes Neurais Profundas para SLAM Visual Robusto},
  author={Santos, Rodrigo Lucas},
  journal={Universidade Federal de Ouro Preto},
  year={2024}
}

ğŸ“š ReferÃªncias

ORB-SLAM2 - Mur-Artal & TardÃ³s, 2017
ORB-SLAM3 - Campos et al., 2021
SuperPoint - DeTone et al., 2018
SuperGlue - Sarlin et al., 2020
MiDaS - Ranftl et al., 2021
DROID-SLAM - Teed & Deng, 2021


ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, leia o CONTRIBUTING.md para detalhes.

Fork o repositÃ³rio

Crie sua branch (git checkout -b feature/nova-feature)
Commit suas mudanÃ§as (git commit -m 'Adiciona nova feature')
Push para a branch (git push origin feature/nova-feature)
Abra um Pull Request


ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo LICENSE para detalhes.

ğŸ‘¤ Autor

Rodrigo Lucas Santos

ğŸ“§ Email: rodrigo.lucas@aluno.ufop.edu.br
ğŸ›ï¸ InstituiÃ§Ã£o: Universidade Federal de Ouro Preto (UFOP)
ğŸ”¬ Departamento: Departamento de ComputaÃ§Ã£o (DECOM)


ğŸ™ Agradecimentos

Departamento de ComputaÃ§Ã£o da UFOP pelo suporte computacional
Prof. Dr. Eduardo Luz e Vander Freitas
Comunidade open-source pelos projetos base